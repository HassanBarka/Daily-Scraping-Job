[2024-08-04T19:05:41.807+0100] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-04T19:05:41.845+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_etl.indeed_scraper scheduled__2024-08-03T18:00:00+00:00 [queued]>
[2024-08-04T19:05:41.851+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_etl.indeed_scraper scheduled__2024-08-03T18:00:00+00:00 [queued]>
[2024-08-04T19:05:41.851+0100] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-08-04T19:05:41.861+0100] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): indeed_scraper> on 2024-08-03 18:00:00+00:00
[2024-08-04T19:05:41.868+0100] {standard_task_runner.py:63} INFO - Started process 503439 to run task
[2024-08-04T19:05:41.872+0100] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'jobs_etl', 'indeed_scraper', 'scheduled__2024-08-03T18:00:00+00:00', '--job-id', '287', '--raw', '--subdir', 'DAGS_FOLDER/jobs_etl.py', '--cfg-path', '/tmp/tmpzgwj639n']
[2024-08-04T19:05:41.874+0100] {standard_task_runner.py:91} INFO - Job 287: Subtask indeed_scraper
[2024-08-04T19:05:41.942+0100] {task_command.py:426} INFO - Running <TaskInstance: jobs_etl.indeed_scraper scheduled__2024-08-03T18:00:00+00:00 [running]> on host huser
[2024-08-04T19:05:42.050+0100] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='hassounibarka@gmail.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='jobs_etl' AIRFLOW_CTX_TASK_ID='indeed_scraper' AIRFLOW_CTX_EXECUTION_DATE='2024-08-03T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-03T18:00:00+00:00'
[2024-08-04T19:05:42.051+0100] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-04T19:06:01.900+0100] {logging_mixin.py:188} INFO - 2 Jobs found for data Scientist
[2024-08-04T19:06:24.034+0100] {logging_mixin.py:188} INFO - 4 Jobs found for data analyst
[2024-08-04T19:06:46.254+0100] {logging_mixin.py:188} INFO - 6 Jobs found for data engineer
[2024-08-04T19:07:11.655+0100] {logging_mixin.py:188} INFO - 22 Jobs found for web developer
[2024-08-04T19:07:34.835+0100] {logging_mixin.py:188} INFO - 4 Jobs found for mobile developer
[2024-08-04T19:22:02.935+0100] {logging_mixin.py:188} INFO - 1 jobs extracted!2 jobs extracted!3 jobs extracted!4 jobs extracted!5 jobs extracted!6 jobs extracted!7 jobs extracted!8 jobs extracted!9 jobs extracted!10 jobs extracted!11 jobs extracted!12 jobs extracted!13 jobs extracted!14 jobs extracted!15 jobs extracted!16 jobs extracted!17 jobs extracted!18 jobs extracted!19 jobs extracted!20 jobs extracted!21 jobs extracted!22 jobs extracted!23 jobs extracted!24 jobs extracted!25 jobs extracted!26 jobs extracted!27 jobs extracted!28 jobs extracted!29 jobs extracted!30 jobs extracted!31 jobs extracted!32 jobs extracted!33 jobs extracted!34 jobs extracted!35 jobs extracted!36 jobs extracted!37 jobs extracted!38 jobs extracted!Done!
[2024-08-04T19:22:02.936+0100] {python.py:237} INFO - Done. Returned value was: None
[2024-08-04T19:22:02.937+0100] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-04T19:22:02.953+0100] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=jobs_etl, task_id=indeed_scraper, run_id=scheduled__2024-08-03T18:00:00+00:00, execution_date=20240803T180000, start_date=20240804T180541, end_date=20240804T182202
[2024-08-04T19:22:03.019+0100] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-08-04T19:22:03.055+0100] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-08-04T19:22:03.057+0100] {local_task_job_runner.py:222} INFO - ::endgroup::
