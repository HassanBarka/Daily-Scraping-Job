[2024-08-20T20:18:29.187+0100] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-20T20:18:29.216+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-19T18:00:00+00:00 [queued]>
[2024-08-20T20:18:29.223+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-19T18:00:00+00:00 [queued]>
[2024-08-20T20:18:29.223+0100] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-08-20T20:18:29.233+0100] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): glassdoor_scraper> on 2024-08-19 18:00:00+00:00
[2024-08-20T20:18:29.245+0100] {standard_task_runner.py:63} INFO - Started process 133108 to run task
[2024-08-20T20:18:29.249+0100] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'jobs_etl', 'glassdoor_scraper', 'scheduled__2024-08-19T18:00:00+00:00', '--job-id', '413', '--raw', '--subdir', 'DAGS_FOLDER/jobs_etl.py', '--cfg-path', '/tmp/tmp0v7wagq6']
[2024-08-20T20:18:29.251+0100] {standard_task_runner.py:91} INFO - Job 413: Subtask glassdoor_scraper
[2024-08-20T20:18:29.319+0100] {task_command.py:426} INFO - Running <TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-19T18:00:00+00:00 [running]> on host huser
[2024-08-20T20:18:29.429+0100] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='hassounibarka@gmail.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='jobs_etl' AIRFLOW_CTX_TASK_ID='glassdoor_scraper' AIRFLOW_CTX_EXECUTION_DATE='2024-08-19T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-19T18:00:00+00:00'
[2024-08-20T20:18:29.429+0100] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-20T20:19:09.211+0100] {logging_mixin.py:188} INFO - 17 jobs found for data Scientist
[2024-08-20T20:23:35.781+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted16 jobs found for data analyst
[2024-08-20T20:28:25.794+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted20 jobs found for data engineer
[2024-08-20T20:33:58.709+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted20 jobs found for web developer
[2024-08-20T20:34:51.304+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extractedNo more
[2024-08-20T20:35:38.687+0100] {logging_mixin.py:188} INFO - 4 Jobs extracted5 Jobs extracted6 Jobs extractedNo more
[2024-08-20T20:36:48.511+0100] {logging_mixin.py:188} INFO - 7 Jobs extracted8 Jobs extracted9 Jobs extractedNo more
[2024-08-20T20:39:36.811+0100] {logging_mixin.py:188} INFO - 10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extractedNo more
[2024-08-20T20:40:39.300+0100] {logging_mixin.py:188} INFO - 20 Jobs extracted0 jobs found for mobile developer
[2024-08-20T20:40:39.400+0100] {logging_mixin.py:188} INFO - Done!
[2024-08-20T20:40:39.401+0100] {python.py:237} INFO - Done. Returned value was: None
[2024-08-20T20:40:39.401+0100] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-20T20:40:39.426+0100] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=jobs_etl, task_id=glassdoor_scraper, run_id=scheduled__2024-08-19T18:00:00+00:00, execution_date=20240819T180000, start_date=20240820T191829, end_date=20240820T194039
[2024-08-20T20:40:39.509+0100] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-08-20T20:40:39.562+0100] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-08-20T20:40:39.563+0100] {local_task_job_runner.py:222} INFO - ::endgroup::
