[2024-08-06T20:50:27.488+0100] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-06T20:50:27.525+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-05T18:00:00+00:00 [queued]>
[2024-08-06T20:50:27.533+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-05T18:00:00+00:00 [queued]>
[2024-08-06T20:50:27.533+0100] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-08-06T20:50:27.547+0100] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): glassdoor_scraper> on 2024-08-05 18:00:00+00:00
[2024-08-06T20:50:27.556+0100] {standard_task_runner.py:63} INFO - Started process 652029 to run task
[2024-08-06T20:50:27.561+0100] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'jobs_etl', 'glassdoor_scraper', 'scheduled__2024-08-05T18:00:00+00:00', '--job-id', '305', '--raw', '--subdir', 'DAGS_FOLDER/jobs_etl.py', '--cfg-path', '/tmp/tmpg1epbuhg']
[2024-08-06T20:50:27.564+0100] {standard_task_runner.py:91} INFO - Job 305: Subtask glassdoor_scraper
[2024-08-06T20:50:27.654+0100] {task_command.py:426} INFO - Running <TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-05T18:00:00+00:00 [running]> on host huser
[2024-08-06T20:50:27.804+0100] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='hassounibarka@gmail.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='jobs_etl' AIRFLOW_CTX_TASK_ID='glassdoor_scraper' AIRFLOW_CTX_EXECUTION_DATE='2024-08-05T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-05T18:00:00+00:00'
[2024-08-06T20:50:27.805+0100] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-06T20:52:20.361+0100] {logging_mixin.py:188} INFO - 20 jobs found for data Scientist
[2024-08-06T20:53:18.691+0100] {logging_mixin.py:188} INFO - 1 Jobs extractedNo more
[2024-08-06T21:14:15.632+0100] {logging_mixin.py:188} INFO - 2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted20 jobs found for data analyst
[2024-08-06T21:27:03.060+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted20 jobs found for data engineer
[2024-08-06T21:31:48.064+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extractedNo more
[2024-08-06T21:42:09.452+0100] {logging_mixin.py:188} INFO - 8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extractedKeyword error
[2024-08-06T21:42:09.578+0100] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-06T21:42:09.580+0100] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/huser/airflow_workspace/airflow/dags/jobs_etl.py", line 31, in get_glassdoor_data
    df = glassdoor_scraper.get_datas(Keywords)
  File "/home/huser/airflow_workspace/airflow/dags/Jobs/GlassdoorScraper.py", line 143, in get_datas
    links = get_links(key)
  File "/home/huser/airflow_workspace/airflow/dags/Jobs/GlassdoorScraper.py", line 69, in get_links
    return Links
UnboundLocalError: local variable 'Links' referenced before assignment
[2024-08-06T21:42:09.606+0100] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=jobs_etl, task_id=glassdoor_scraper, run_id=scheduled__2024-08-05T18:00:00+00:00, execution_date=20240805T180000, start_date=20240806T195027, end_date=20240806T204209
[2024-08-06T21:42:09.628+0100] {standard_task_runner.py:110} ERROR - Failed to execute job 305 for task glassdoor_scraper (local variable 'Links' referenced before assignment; 652029)
[2024-08-06T21:42:09.657+0100] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-08-06T21:42:09.698+0100] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-08-06T21:42:09.701+0100] {local_task_job_runner.py:222} INFO - ::endgroup::
