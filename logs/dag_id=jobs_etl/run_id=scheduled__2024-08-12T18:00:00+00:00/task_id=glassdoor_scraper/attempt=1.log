[2024-08-13T20:52:34.757+0100] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-13T20:52:34.809+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-12T18:00:00+00:00 [queued]>
[2024-08-13T20:52:34.816+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-12T18:00:00+00:00 [queued]>
[2024-08-13T20:52:34.816+0100] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-08-13T20:52:34.826+0100] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): glassdoor_scraper> on 2024-08-12 18:00:00+00:00
[2024-08-13T20:52:34.835+0100] {standard_task_runner.py:63} INFO - Started process 1088948 to run task
[2024-08-13T20:52:34.839+0100] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'jobs_etl', 'glassdoor_scraper', 'scheduled__2024-08-12T18:00:00+00:00', '--job-id', '364', '--raw', '--subdir', 'DAGS_FOLDER/jobs_etl.py', '--cfg-path', '/tmp/tmp_or3iu5e']
[2024-08-13T20:52:34.841+0100] {standard_task_runner.py:91} INFO - Job 364: Subtask glassdoor_scraper
[2024-08-13T20:52:34.908+0100] {task_command.py:426} INFO - Running <TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-12T18:00:00+00:00 [running]> on host huser
[2024-08-13T20:52:35.012+0100] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='hassounibarka@gmail.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='jobs_etl' AIRFLOW_CTX_TASK_ID='glassdoor_scraper' AIRFLOW_CTX_EXECUTION_DATE='2024-08-12T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-12T18:00:00+00:00'
[2024-08-13T20:52:35.013+0100] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-13T20:52:40.236+0100] {selenium_manager.py:127} WARNING - Exception managing chrome: error sending request for url (https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json)
[2024-08-13T20:52:40.237+0100] {selenium_manager.py:127} WARNING - Error sending stats to Plausible: error sending request for url (https://plausible.io/api/event)
[2024-08-13T20:54:44.035+0100] {logging_mixin.py:188} INFO - 19 jobs found for data Scientist
[2024-08-13T21:14:59.791+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted16 jobs found for data analyst
[2024-08-13T21:40:42.696+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted20 jobs found for data engineer
[2024-08-13T21:55:52.166+0100] {selenium_manager.py:127} WARNING - Exception managing chrome: error sending request for url (https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json)
[2024-08-13T21:59:42.521+0100] {logging_mixin.py:188} INFO - 2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted20 jobs found for web developer
[2024-08-13T22:01:10.050+0100] {logging_mixin.py:188} INFO - 1 Jobs extractedNo more
[2024-08-13T22:01:49.851+0100] {logging_mixin.py:188} INFO - 2 Jobs extractedNo more
[2024-08-13T22:03:52.507+0100] {logging_mixin.py:188} INFO - 3 Jobs extracted4 Jobs extracted5 Jobs extractedNo more
[2024-08-13T22:07:17.452+0100] {logging_mixin.py:188} INFO - 6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extractedNo more
[2024-08-13T22:14:01.580+0100] {logging_mixin.py:188} INFO - 10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted15 jobs found for mobile developer
[2024-08-13T22:16:04.254+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extractedNo more
[2024-08-13T22:18:26.534+0100] {logging_mixin.py:188} INFO - 5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extractedNo more
[2024-08-13T22:18:46.923+0100] {logging_mixin.py:188} INFO - 12 Jobs extractedNo more
[2024-08-13T22:19:55.333+0100] {logging_mixin.py:188} INFO - 13 Jobs extracted14 Jobs extracted15 Jobs extractedDone!
[2024-08-13T22:19:55.333+0100] {python.py:237} INFO - Done. Returned value was: None
[2024-08-13T22:19:55.334+0100] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-13T22:19:55.351+0100] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=jobs_etl, task_id=glassdoor_scraper, run_id=scheduled__2024-08-12T18:00:00+00:00, execution_date=20240812T180000, start_date=20240813T195234, end_date=20240813T211955
[2024-08-13T22:19:55.418+0100] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-08-13T22:19:55.451+0100] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-08-13T22:19:55.452+0100] {local_task_job_runner.py:222} INFO - ::endgroup::
