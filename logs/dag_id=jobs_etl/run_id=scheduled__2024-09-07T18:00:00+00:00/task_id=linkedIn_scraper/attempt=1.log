[2024-09-08T20:07:02.567+0100] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-09-08T20:07:02.614+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_etl.linkedIn_scraper scheduled__2024-09-07T18:00:00+00:00 [queued]>
[2024-09-08T20:07:02.624+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_etl.linkedIn_scraper scheduled__2024-09-07T18:00:00+00:00 [queued]>
[2024-09-08T20:07:02.625+0100] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-09-08T20:07:02.640+0100] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): linkedIn_scraper> on 2024-09-07 18:00:00+00:00
[2024-09-08T20:07:02.654+0100] {standard_task_runner.py:63} INFO - Started process 204006 to run task
[2024-09-08T20:07:02.660+0100] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'jobs_etl', 'linkedIn_scraper', 'scheduled__2024-09-07T18:00:00+00:00', '--job-id', '434', '--raw', '--subdir', 'DAGS_FOLDER/jobs_etl.py', '--cfg-path', '/tmp/tmpmanf2726']
[2024-09-08T20:07:02.662+0100] {standard_task_runner.py:91} INFO - Job 434: Subtask linkedIn_scraper
[2024-09-08T20:07:02.767+0100] {task_command.py:426} INFO - Running <TaskInstance: jobs_etl.linkedIn_scraper scheduled__2024-09-07T18:00:00+00:00 [running]> on host huser
[2024-09-08T20:07:02.929+0100] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='hassounibarka@gmail.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='jobs_etl' AIRFLOW_CTX_TASK_ID='linkedIn_scraper' AIRFLOW_CTX_EXECUTION_DATE='2024-09-07T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-09-07T18:00:00+00:00'
[2024-09-08T20:07:02.930+0100] {taskinstance.py:430} INFO - ::endgroup::
[2024-09-08T20:08:05.019+0100] {logging_mixin.py:188} INFO - number_of_jobs: 333
[2024-09-08T20:08:05.020+0100] {logging_mixin.py:188} INFO - number_of_pages: 14
[2024-09-08T20:08:05.020+0100] {logging_mixin.py:188} INFO - Scraping page: 1
[2024-09-08T20:08:05.027+0100] {logging_mixin.py:188} INFO - done!
[2024-09-08T20:08:05.028+0100] {logging_mixin.py:188} INFO - Scraping page: 2
[2024-09-08T20:08:14.611+0100] {logging_mixin.py:188} INFO - done!
[2024-09-08T20:08:14.612+0100] {logging_mixin.py:188} INFO - Scraping page: 3
[2024-09-08T20:08:23.276+0100] {logging_mixin.py:188} INFO - done!
[2024-09-08T20:08:23.277+0100] {logging_mixin.py:188} INFO - Scraping page: 4
[2024-09-08T20:08:32.279+0100] {logging_mixin.py:188} INFO - done!
[2024-09-08T20:08:32.279+0100] {logging_mixin.py:188} INFO - Scraping page: 5
[2024-09-08T22:19:24.926+0100] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to restarting. Terminating instance.
[2024-09-08T22:19:24.930+0100] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-09-08T22:19:24.950+0100] {process_utils.py:132} INFO - Sending 15 to group 204006. PIDs of all processes in the group: [204029, 204035, 204039, 204040, 204050, 204051, 204080, 204172, 204053, 204081, 204137, 204578, 204611, 204639, 204648, 204077, 204006]
[2024-09-08T22:19:24.951+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 204006
[2024-09-08T22:19:24.974+0100] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-09-08T22:19:24.980+0100] {logging_mixin.py:188} INFO - 1 Jobs read2 Jobs read3 Jobs read4 Jobs read5 Jobs read6 Jobs read7 Jobs read8 Jobs read9 Jobs read10 Jobs read11 Jobs read12 error read Job ID: None
[2024-09-08T22:19:24.994+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204039, status='terminated', started='20:07:03') (204039) terminated with exit code None
[2024-09-08T22:19:24.999+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204040, status='terminated', started='20:07:03') (204040) terminated with exit code None
[2024-09-08T22:19:25.023+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204035, status='terminated', started='20:07:03') (204035) terminated with exit code None
[2024-09-08T22:19:25.055+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204051, status='terminated', started='20:07:03') (204051) terminated with exit code None
[2024-09-08T22:19:25.056+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204648, status='terminated', started='20:08:45') (204648) terminated with exit code None
[2024-09-08T22:19:25.119+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204639, status='terminated', started='20:08:44') (204639) terminated with exit code None
[2024-09-08T22:19:25.121+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204578, status='terminated', started='20:08:26') (204578) terminated with exit code None
[2024-09-08T22:19:25.123+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204081, status='terminated', started='20:07:04') (204081) terminated with exit code None
[2024-09-08T22:19:25.123+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204172, status='terminated', started='20:07:08') (204172) terminated with exit code None
[2024-09-08T22:19:25.124+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204053, status='terminated', started='20:07:03') (204053) terminated with exit code None
[2024-09-08T22:19:25.124+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204611, status='terminated', started='20:08:35') (204611) terminated with exit code None
[2024-09-08T22:19:25.125+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204050, status='terminated', started='20:07:03') (204050) terminated with exit code None
[2024-09-08T22:19:25.126+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204137, status='terminated', started='20:07:04') (204137) terminated with exit code None
[2024-09-08T22:19:25.126+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204077, status='terminated', started='20:07:04') (204077) terminated with exit code None
[2024-09-08T22:19:25.126+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204080, status='terminated', started='20:07:04') (204080) terminated with exit code None
[2024-09-08T22:19:56.966+0100] {logging_mixin.py:188} INFO - 13 Jobs read14 Jobs read15 Jobs read16 Jobs read17 Jobs read18 Jobs read19 Jobs read20 Jobs read21 Jobs read22 Jobs read23 Jobs read24 Jobs read25 error read Job ID: None
[2024-09-08T22:19:56.971+0100] {logging_mixin.py:188} INFO - 26 error read Job ID: None
[2024-09-08T22:19:56.973+0100] {logging_mixin.py:188} INFO - 27 error read Job ID: None
[2024-09-08T22:19:56.977+0100] {logging_mixin.py:188} INFO - 28 error read Job ID: None
[2024-09-08T22:19:56.979+0100] {logging_mixin.py:188} INFO - 29 error read Job ID: None
[2024-09-08T22:19:56.983+0100] {logging_mixin.py:188} INFO - 30 error read Job ID: None
[2024-09-08T22:19:56.987+0100] {logging_mixin.py:188} INFO - 31 error read Job ID: None
[2024-09-08T22:19:56.989+0100] {logging_mixin.py:188} INFO - 32 error read Job ID: None
[2024-09-08T22:19:56.992+0100] {logging_mixin.py:188} INFO - 33 error read Job ID: None
[2024-09-08T22:19:56.995+0100] {logging_mixin.py:188} INFO - 34 error read Job ID: None
[2024-09-08T22:19:56.997+0100] {logging_mixin.py:188} INFO - 35 error read Job ID: None
[2024-09-08T22:19:57.001+0100] {logging_mixin.py:188} INFO - 36 error read Job ID: None
[2024-09-08T22:19:57.005+0100] {logging_mixin.py:188} INFO - 37 error read Job ID: None
[2024-09-08T22:19:57.007+0100] {logging_mixin.py:188} INFO - 38 error read Job ID: None
[2024-09-08T22:19:57.009+0100] {logging_mixin.py:188} INFO - 39 error read Job ID: None
[2024-09-08T22:19:57.012+0100] {logging_mixin.py:188} INFO - 40 error read Job ID: None
[2024-09-08T22:19:57.016+0100] {logging_mixin.py:188} INFO - 41 error read Job ID: None
[2024-09-08T22:19:57.019+0100] {logging_mixin.py:188} INFO - 42 error read Job ID: None
[2024-09-08T22:19:57.021+0100] {logging_mixin.py:188} INFO - 43 error read Job ID: None
[2024-09-08T22:19:57.023+0100] {logging_mixin.py:188} INFO - 44 error read Job ID: None
[2024-09-08T22:19:57.026+0100] {logging_mixin.py:188} INFO - 45 error read Job ID: None
[2024-09-08T22:19:57.028+0100] {logging_mixin.py:188} INFO - 46 error read Job ID: None
[2024-09-08T22:19:57.031+0100] {logging_mixin.py:188} INFO - 47 error read Job ID: None
[2024-09-08T22:19:57.034+0100] {logging_mixin.py:188} INFO - 48 error read Job ID: None
[2024-09-08T22:19:57.037+0100] {logging_mixin.py:188} INFO - 49 error read Job ID: None
[2024-09-08T22:19:57.040+0100] {logging_mixin.py:188} INFO - 50 error read Job ID: None
[2024-09-08T22:19:57.042+0100] {logging_mixin.py:188} INFO - 51 error read Job ID: None
[2024-09-08T22:19:57.045+0100] {logging_mixin.py:188} INFO - 52 error read Job ID: None
[2024-09-08T22:19:57.047+0100] {logging_mixin.py:188} INFO - 53 error read Job ID: None
[2024-09-08T22:19:57.049+0100] {logging_mixin.py:188} INFO - 54 error read Job ID: None
[2024-09-08T22:19:57.052+0100] {logging_mixin.py:188} INFO - 55 error read Job ID: None
[2024-09-08T22:19:57.054+0100] {logging_mixin.py:188} INFO - 56 error read Job ID: None
[2024-09-08T22:19:57.056+0100] {logging_mixin.py:188} INFO - 57 error read Job ID: None
[2024-09-08T22:19:57.059+0100] {logging_mixin.py:188} INFO - 58 error read Job ID: None
[2024-09-08T22:19:57.061+0100] {logging_mixin.py:188} INFO - 59 error read Job ID: None
[2024-09-08T22:19:57.064+0100] {logging_mixin.py:188} INFO - 60 error read Job ID: None
[2024-09-08T22:19:57.067+0100] {logging_mixin.py:188} INFO - 61 error read Job ID: None
[2024-09-08T22:19:57.069+0100] {logging_mixin.py:188} INFO - 62 error read Job ID: None
[2024-09-08T22:19:57.072+0100] {logging_mixin.py:188} INFO - 63 error read Job ID: None
[2024-09-08T22:19:57.074+0100] {logging_mixin.py:188} INFO - 64 error read Job ID: None
[2024-09-08T22:19:57.077+0100] {logging_mixin.py:188} INFO - 65 error read Job ID: None
[2024-09-08T22:19:57.080+0100] {logging_mixin.py:188} INFO - 66 error read Job ID: None
[2024-09-08T22:19:57.085+0100] {logging_mixin.py:188} INFO - 67 error read Job ID: None
[2024-09-08T22:19:57.087+0100] {logging_mixin.py:188} INFO - 68 error read Job ID: None
[2024-09-08T22:19:57.091+0100] {logging_mixin.py:188} INFO - 69 error read Job ID: None
[2024-09-08T22:19:57.093+0100] {logging_mixin.py:188} INFO - 70 error read Job ID: None
[2024-09-08T22:19:57.096+0100] {logging_mixin.py:188} INFO - 71 error read Job ID: None
[2024-09-08T22:19:57.100+0100] {logging_mixin.py:188} INFO - 72 error read Job ID: None
[2024-09-08T22:19:57.103+0100] {logging_mixin.py:188} INFO - 73 error read Job ID: None
[2024-09-08T22:19:57.106+0100] {logging_mixin.py:188} INFO - 74 error read Job ID: None
[2024-09-08T22:19:57.109+0100] {logging_mixin.py:188} INFO - 75 error read Job ID: None
[2024-09-08T22:19:57.111+0100] {logging_mixin.py:188} INFO - 76 error read Job ID: None
[2024-09-08T22:19:57.114+0100] {logging_mixin.py:188} INFO - 77 error read Job ID: None
[2024-09-08T22:19:57.119+0100] {logging_mixin.py:188} INFO - 78 error read Job ID: None
[2024-09-08T22:19:57.122+0100] {logging_mixin.py:188} INFO - 79 error read Job ID: None
[2024-09-08T22:19:57.125+0100] {logging_mixin.py:188} INFO - 80 error read Job ID: None
[2024-09-08T22:19:57.127+0100] {logging_mixin.py:188} INFO - 81 error read Job ID: None
[2024-09-08T22:19:57.130+0100] {logging_mixin.py:188} INFO - 82 error read Job ID: None
[2024-09-08T22:19:57.132+0100] {logging_mixin.py:188} INFO - 83 error read Job ID: None
[2024-09-08T22:19:57.136+0100] {logging_mixin.py:188} INFO - 84 error read Job ID: None
[2024-09-08T22:19:57.139+0100] {logging_mixin.py:188} INFO - 85 error read Job ID: None
[2024-09-08T22:19:57.142+0100] {logging_mixin.py:188} INFO - 86 error read Job ID: None
[2024-09-08T22:19:57.145+0100] {logging_mixin.py:188} INFO - 87 error read Job ID: None
[2024-09-08T22:19:57.148+0100] {logging_mixin.py:188} INFO - 88 error read Job ID: None
[2024-09-08T22:19:57.151+0100] {logging_mixin.py:188} INFO - 89 error read Job ID: None
[2024-09-08T22:19:57.154+0100] {logging_mixin.py:188} INFO - 90 error read Job ID: None
[2024-09-08T22:19:57.157+0100] {logging_mixin.py:188} INFO - 91 error read Job ID: None
[2024-09-08T22:19:57.161+0100] {logging_mixin.py:188} INFO - 92 error read Job ID: None
[2024-09-08T22:19:57.163+0100] {logging_mixin.py:188} INFO - 93 error read Job ID: None
[2024-09-08T22:19:57.166+0100] {logging_mixin.py:188} INFO - 94 error read Job ID: None
[2024-09-08T22:19:57.169+0100] {logging_mixin.py:188} INFO - 95 error read Job ID: None
[2024-09-08T22:19:57.173+0100] {logging_mixin.py:188} INFO - 96 error read Job ID: None
[2024-09-08T22:19:57.176+0100] {logging_mixin.py:188} INFO - 97 error read Job ID: None
[2024-09-08T22:19:57.180+0100] {logging_mixin.py:188} INFO - 98 error read Job ID: None
[2024-09-08T22:19:57.184+0100] {logging_mixin.py:188} INFO - 99 error read Job ID: None
[2024-09-08T22:19:57.187+0100] {logging_mixin.py:188} INFO - 100 error read Job ID: None
[2024-09-08T22:19:57.190+0100] {logging_mixin.py:188} INFO - 101 error read Job ID: None
[2024-09-08T22:19:57.194+0100] {logging_mixin.py:188} INFO - 102 error read Job ID: None
[2024-09-08T22:19:57.197+0100] {logging_mixin.py:188} INFO - 103 error read Job ID: None
[2024-09-08T22:19:57.201+0100] {logging_mixin.py:188} INFO - 104 error read Job ID: None
[2024-09-08T22:19:57.204+0100] {logging_mixin.py:188} INFO - 105 error read Job ID: None
[2024-09-08T22:19:57.207+0100] {logging_mixin.py:188} INFO - 106 error read Job ID: None
[2024-09-08T22:19:57.210+0100] {logging_mixin.py:188} INFO - 107 error read Job ID: None
[2024-09-08T22:19:57.212+0100] {logging_mixin.py:188} INFO - 108 error read Job ID: None
[2024-09-08T22:19:57.215+0100] {logging_mixin.py:188} INFO - 109 error read Job ID: None
[2024-09-08T22:19:57.217+0100] {logging_mixin.py:188} INFO - 110 error read Job ID: None
[2024-09-08T22:19:57.219+0100] {logging_mixin.py:188} INFO - 111 error read Job ID: None
[2024-09-08T22:19:57.221+0100] {logging_mixin.py:188} INFO - 112 error read Job ID: None
[2024-09-08T22:19:57.223+0100] {logging_mixin.py:188} INFO - 113 error read Job ID: None
[2024-09-08T22:19:57.225+0100] {logging_mixin.py:188} INFO - 114 error read Job ID: None
[2024-09-08T22:19:57.227+0100] {logging_mixin.py:188} INFO - 115 error read Job ID: None
[2024-09-08T22:19:57.230+0100] {logging_mixin.py:188} INFO - 116 error read Job ID: None
[2024-09-08T22:19:57.232+0100] {logging_mixin.py:188} INFO - 117 error read Job ID: None
[2024-09-08T22:19:57.233+0100] {logging_mixin.py:188} INFO - 118 error read Job ID: None
[2024-09-08T22:19:57.235+0100] {logging_mixin.py:188} INFO - 119 error read Job ID: None
[2024-09-08T22:19:57.238+0100] {logging_mixin.py:188} INFO - 120 error read Job ID: None
[2024-09-08T22:19:57.240+0100] {logging_mixin.py:188} INFO - 121 error read Job ID: None
[2024-09-08T22:19:57.242+0100] {logging_mixin.py:188} INFO - 122 error read Job ID: None
[2024-09-08T22:19:57.248+0100] {logging_mixin.py:188} INFO - 123 error read Job ID: None
[2024-09-08T22:19:57.250+0100] {logging_mixin.py:188} INFO - 124 error read Job ID: None
[2024-09-08T22:19:57.253+0100] {logging_mixin.py:188} INFO - 125 error read Job ID: None
[2024-09-08T22:19:57.259+0100] {connectionpool.py:874} WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0040bc2bc0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /session/21cbbb58b4eef08b9daedbeb20698bf5/url
[2024-09-08T22:19:57.260+0100] {connectionpool.py:874} WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0040443fa0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /session/21cbbb58b4eef08b9daedbeb20698bf5/url
[2024-09-08T22:19:57.261+0100] {connectionpool.py:874} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f00404411e0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /session/21cbbb58b4eef08b9daedbeb20698bf5/url
[2024-09-08T22:19:57.262+0100] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-09-08T22:19:57.262+0100] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py", line 793, in urlopen
    response = self._make_request(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py", line 496, in _make_request
    conn.request(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connection.py", line 400, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connection.py", line 238, in connect
    self.sock = self._new_conn()
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f0040440d00>: Failed to establish a new connection: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/huser/airflow_workspace/airflow/dags/jobs_etl.py", line 42, in get_linked_data
    df = linked_scraper.get_datas(driver,Keywords,Locations)
  File "/home/huser/airflow_workspace/airflow/dags/Jobs/LinkedScrper.py", line 188, in get_datas
    df = get_data(driver,keyword,location)
  File "/home/huser/airflow_workspace/airflow/dags/Jobs/LinkedScrper.py", line 71, in get_data
    number_of_pages, soup = nb_of_page(driver,url)
  File "/home/huser/airflow_workspace/airflow/dags/Jobs/LinkedScrper.py", line 32, in nb_of_page
    driver.get(url)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 363, in get
    self.execute(Command.GET, {"url": url})
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 352, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/_request_methods.py", line 144, in request
    return self.request_encode_body(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/_request_methods.py", line 279, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/poolmanager.py", line 444, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py", line 877, in urlopen
    return self.urlopen(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py", line 877, in urlopen
    return self.urlopen(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py", line 877, in urlopen
    return self.urlopen(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py", line 847, in urlopen
    retries = retries.increment(
  File "/home/huser/airflow_workspace/airflow_env/lib/python3.10/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=57157): Max retries exceeded with url: /session/21cbbb58b4eef08b9daedbeb20698bf5/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0040440d00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[2024-09-08T22:19:57.302+0100] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=jobs_etl, task_id=linkedIn_scraper, run_id=scheduled__2024-09-07T18:00:00+00:00, execution_date=20240907T180000, start_date=20240908T190702, end_date=20240908T211957
[2024-09-08T22:19:57.322+0100] {standard_task_runner.py:110} ERROR - Failed to execute job 434 for task linkedIn_scraper (HTTPConnectionPool(host='localhost', port=57157): Max retries exceeded with url: /session/21cbbb58b4eef08b9daedbeb20698bf5/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0040440d00>: Failed to establish a new connection: [Errno 101] Network is unreachable')); 204006)
[2024-09-08T22:19:57.396+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204029, status='terminated', started='20:07:02') (204029) terminated with exit code None
[2024-09-08T22:19:57.396+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=204006, status='terminated', exitcode=1, started='20:07:02') (204006) terminated with exit code 1
