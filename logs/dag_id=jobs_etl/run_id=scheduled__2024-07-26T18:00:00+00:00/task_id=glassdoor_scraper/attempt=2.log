[2024-07-27T21:05:17.471+0100] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-27T21:05:17.505+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-07-26T18:00:00+00:00 [queued]>
[2024-07-27T21:05:17.514+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-07-26T18:00:00+00:00 [queued]>
[2024-07-27T21:05:17.514+0100] {taskinstance.py:2306} INFO - Starting attempt 2 of 3
[2024-07-27T21:05:17.525+0100] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): glassdoor_scraper> on 2024-07-26 18:00:00+00:00
[2024-07-27T21:05:17.535+0100] {standard_task_runner.py:63} INFO - Started process 54980 to run task
[2024-07-27T21:05:17.540+0100] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'jobs_etl', 'glassdoor_scraper', 'scheduled__2024-07-26T18:00:00+00:00', '--job-id', '230', '--raw', '--subdir', 'DAGS_FOLDER/jobs_etl.py', '--cfg-path', '/tmp/tmp7crzfzub']
[2024-07-27T21:05:17.543+0100] {standard_task_runner.py:91} INFO - Job 230: Subtask glassdoor_scraper
[2024-07-27T21:05:17.620+0100] {task_command.py:426} INFO - Running <TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-07-26T18:00:00+00:00 [running]> on host huser
[2024-07-27T21:05:17.743+0100] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='hassounibarka@gmail.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='jobs_etl' AIRFLOW_CTX_TASK_ID='glassdoor_scraper' AIRFLOW_CTX_EXECUTION_DATE='2024-07-26T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-26T18:00:00+00:00'
[2024-07-27T21:05:17.745+0100] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-27T21:07:20.230+0100] {logging_mixin.py:188} INFO - 14 jobs found for data Scientist
[2024-07-27T21:19:02.383+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted16 jobs found for data analyst
[2024-07-27T21:22:31.219+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 jobs found for data engineer
[2024-07-27T21:26:14.885+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted20 jobs found for web developer
[2024-07-27T21:35:23.386+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted14 jobs found for mobile developer
[2024-07-27T21:38:23.746+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extractedDone!
[2024-07-27T21:38:23.747+0100] {python.py:237} INFO - Done. Returned value was: None
[2024-07-27T21:38:23.747+0100] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-27T21:38:23.765+0100] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=jobs_etl, task_id=glassdoor_scraper, run_id=scheduled__2024-07-26T18:00:00+00:00, execution_date=20240726T180000, start_date=20240727T200517, end_date=20240727T203823
[2024-07-27T21:38:23.823+0100] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-27T21:38:23.867+0100] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-07-27T21:38:23.868+0100] {local_task_job_runner.py:222} INFO - ::endgroup::
