[2024-08-08T20:08:29.621+0100] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-08T20:08:29.668+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-07T18:00:00+00:00 [queued]>
[2024-08-08T20:08:29.676+0100] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-07T18:00:00+00:00 [queued]>
[2024-08-08T20:08:29.676+0100] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-08-08T20:08:29.691+0100] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): glassdoor_scraper> on 2024-08-07 18:00:00+00:00
[2024-08-08T20:08:29.709+0100] {standard_task_runner.py:63} INFO - Started process 797887 to run task
[2024-08-08T20:08:29.713+0100] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'jobs_etl', 'glassdoor_scraper', 'scheduled__2024-08-07T18:00:00+00:00', '--job-id', '321', '--raw', '--subdir', 'DAGS_FOLDER/jobs_etl.py', '--cfg-path', '/tmp/tmp85gp8x7x']
[2024-08-08T20:08:29.716+0100] {standard_task_runner.py:91} INFO - Job 321: Subtask glassdoor_scraper
[2024-08-08T20:08:29.813+0100] {task_command.py:426} INFO - Running <TaskInstance: jobs_etl.glassdoor_scraper scheduled__2024-08-07T18:00:00+00:00 [running]> on host huser
[2024-08-08T20:08:29.960+0100] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='hassounibarka@gmail.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='jobs_etl' AIRFLOW_CTX_TASK_ID='glassdoor_scraper' AIRFLOW_CTX_EXECUTION_DATE='2024-08-07T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-07T18:00:00+00:00'
[2024-08-08T20:08:29.961+0100] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-08T20:09:31.098+0100] {selenium_manager.py:127} WARNING - Error sending stats to Plausible: error sending request for url (https://plausible.io/api/event)
[2024-08-08T20:10:43.375+0100] {logging_mixin.py:188} INFO - 15 jobs found for data Scientist
[2024-08-08T20:19:42.935+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extractedNo more
[2024-08-08T20:22:44.988+0100] {logging_mixin.py:188} INFO - 13 Jobs extracted14 Jobs extracted15 Jobs extracted11 jobs found for data analyst
[2024-08-08T20:34:41.887+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted20 jobs found for data engineer
[2024-08-08T20:38:33.059+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extractedNo more
[2024-08-08T20:49:48.496+0100] {logging_mixin.py:188} INFO - 6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extractedNo more
[2024-08-08T20:56:00.793+0100] {logging_mixin.py:188} INFO - 14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted20 jobs found for web developer
[2024-08-08T20:59:04.775+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extractedNo more
[2024-08-08T21:15:46.753+0100] {logging_mixin.py:188} INFO - 4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extracted15 Jobs extracted16 Jobs extracted17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extracted20 jobs found for mobile developer
[2024-08-08T21:16:24.626+0100] {logging_mixin.py:188} INFO - No more
[2024-08-08T21:24:21.931+0100] {logging_mixin.py:188} INFO - 1 Jobs extracted2 Jobs extracted3 Jobs extracted4 Jobs extracted5 Jobs extracted6 Jobs extracted7 Jobs extracted8 Jobs extracted9 Jobs extracted10 Jobs extracted11 Jobs extracted12 Jobs extracted13 Jobs extracted14 Jobs extractedNo more
[2024-08-08T21:25:11.715+0100] {logging_mixin.py:188} INFO - 15 Jobs extracted16 Jobs extractedNo more
[2024-08-08T21:26:25.182+0100] {logging_mixin.py:188} INFO - 17 Jobs extracted18 Jobs extracted19 Jobs extracted20 Jobs extractedDone!
[2024-08-08T21:26:25.184+0100] {python.py:237} INFO - Done. Returned value was: None
[2024-08-08T21:26:25.185+0100] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-08T21:26:25.207+0100] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=jobs_etl, task_id=glassdoor_scraper, run_id=scheduled__2024-08-07T18:00:00+00:00, execution_date=20240807T180000, start_date=20240808T190829, end_date=20240808T202625
[2024-08-08T21:26:25.278+0100] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-08-08T21:26:25.323+0100] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-08-08T21:26:25.326+0100] {local_task_job_runner.py:222} INFO - ::endgroup::
